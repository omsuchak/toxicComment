{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "removing collection member with no package: hmm_treebank_pos_tagger\n",
      "removing collection member with no package: hmm_treebank_pos_tagger\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/omsuchak/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import  division\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    " \n",
    " \n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "#import xgboost as xgb\n",
    "from sklearn import* \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import ensemble, metrics, model_selection, naive_bayes\n",
    " \n",
    "\n",
    "eng_stopwords = set(stopwords.words(\"english\"))\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "sample = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "coly = [c for c in train.columns if c not in ['id','comment_text']]\n",
    "y = train[coly]\n",
    "test_id = test['id'].values\n",
    "\n",
    "df = pd.concat([train['comment_text'], test['comment_text']], axis=0)\n",
    "df = df.fillna(\"unknown\")\n",
    "nrow = train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def  remove(txt):\n",
    "    result = ''.join([i for i in txt if not i.isdigit()])\n",
    "    return result\n",
    "train_df=train_df.fillna('kinetic')\n",
    "test_df=test_df.fillna('kinetic')\n",
    "def  kinetic(row):\n",
    "    probs=np.unique(row,return_counts=True)[1]/len(row)\n",
    "    kinetic=np.sum(probs**2)\n",
    "    return kinetic\n",
    "\n",
    "# def kinetic_letters(text):\n",
    "#     text = text.lower()\n",
    "#     letterRepartition = np.zeros(26)\n",
    "#     i = 0\n",
    "#     for letter in text:\n",
    "#         if ord(letter) in range(97, 123) :\n",
    "#             letterRepartition[ord(letter)-97] +=1 \n",
    "#     probs = letterRepartition/len(text)\n",
    "#     kinetic = np.sum(probs**2)\n",
    "#     return kinetic\n",
    "    \n",
    "def kinetic_letters(text):\n",
    " \n",
    "    letterRepartition = np.zeros(26)\n",
    "    for letter in text:\n",
    "        if ord(letter) in range(97, 123) :\n",
    "            letterRepartition[ord(letter)-97] +=1\n",
    "    letterRepartition = letterRepartition / len(text)\n",
    "    return kinetic(letterRepartition)\n",
    "\n",
    "def kinetic_voals(text):\n",
    "  \n",
    "    letterRepartition = np.zeros(26)\n",
    "    for letter in text:\n",
    "        if ord(letter) in range(97, 123) :\n",
    "            letterRepartition[ord(letter)-97] +=1 \n",
    "            \n",
    "    letterRepartition = letterRepartition / len(text)       \n",
    "    return kinetic(letterRepartition[[0, 4, 8, 14, 20, 24]])\n",
    "\n",
    "def kinetic_cons(text):\n",
    "   \n",
    "    letterRepartition = np.zeros(26)\n",
    "    for letter in text:\n",
    "        if ord(letter) in range(97, 123) :\n",
    "            letterRepartition[ord(letter)-97] +=1 \n",
    "    letterRepartition = letterRepartition / len(text)\n",
    "    return kinetic(letterRepartition[[1, 2, 3 , 5, 6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18 ,19 , 21, 22, \n",
    "                                     23, 25]])\n",
    "\n",
    "def kinetic_ponct(text):\n",
    " \n",
    "    ponct_list = list(['.', ',', ';', '?', '!'])\n",
    "    ponct_repart = np.zeros(5)\n",
    "    for letter in text:\n",
    "        if letter in ponct_list:\n",
    "            ponct_repart[ponct_list.index(letter)] += 1\n",
    "    ponct_repart = ponct_repart / len(text)\n",
    "    return kinetic(ponct_repart)\n",
    "\n",
    "def kinetic_average_words(text):\n",
    "   \n",
    "    ponct_list = list(['.', ',', ';', '?', '!'])\n",
    "    for ponct in ponct_list:\n",
    "        text = text.replace(ponct, '')\n",
    "    text = text.split(' ')\n",
    "    avg_kin = 0\n",
    "    for word in text:\n",
    "        avg_kin += kinetic_letters(word)\n",
    "    return avg_kin/len(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "5        0\n",
      "6        0\n",
      "7        0\n",
      "8        0\n",
      "9        0\n",
      "10       0\n",
      "11       0\n",
      "12       0\n",
      "13       0\n",
      "14       0\n",
      "15       0\n",
      "16       0\n",
      "17       0\n",
      "18       0\n",
      "19       0\n",
      "20       0\n",
      "21       0\n",
      "22       0\n",
      "23       0\n",
      "24       0\n",
      "25       0\n",
      "26       0\n",
      "27       0\n",
      "28       0\n",
      "29       0\n",
      "        ..\n",
      "95821    0\n",
      "95822    0\n",
      "95823    0\n",
      "95824    0\n",
      "95825    0\n",
      "95826    0\n",
      "95827    0\n",
      "95828    0\n",
      "95829    0\n",
      "95830    0\n",
      "95831    0\n",
      "95832    0\n",
      "95833    0\n",
      "95834    0\n",
      "95835    0\n",
      "95836    0\n",
      "95837    0\n",
      "95838    0\n",
      "95839    0\n",
      "95840    0\n",
      "95841    0\n",
      "95842    0\n",
      "95843    0\n",
      "95844    0\n",
      "95845    0\n",
      "95846    0\n",
      "95847    0\n",
      "95848    0\n",
      "95849    0\n",
      "95850    0\n",
      "Name: comment_text, Length: 95851, dtype: int64\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1d62187259ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m## kinetic in letters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"kinetic_letters\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"comment_text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkinetic_letters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"kinetic_letters\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"comment_text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkinetic_letters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2353\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2355\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2357\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer (pandas/_libs/lib.c:66440)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-f45bb2f8ebe5>\u001b[0m in \u001b[0;36mkinetic_letters\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mletterRepartition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m26\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mletter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mletter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m97\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m123\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mletterRepartition\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mletter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m97\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not iterable"
     ]
    }
   ],
   "source": [
    "print(train_df[\"comment_text\"].apply(kinetic_average_words))\n",
    "\n",
    "\n",
    "## kinetic in letters\n",
    "train_df[\"kinetic_letters\"] = train_df[\"comment_text\"].apply(kinetic_letters)\n",
    "test_df[\"kinetic_letters\"] = test_df[\"comment_text\"].apply(kinetic_letters)\n",
    "\n",
    "done = 1\n",
    "print (\"done:\", done)\n",
    "done+=1\n",
    "## kinetic in voals\n",
    "train_df[\"kinetic_voals\"] = train_df[\"comment_text\"].apply(kinetic_voals)\n",
    "test_df[\"kinetic_voals\"] = test_df[\"comment_text\"].apply(kinetic_voals)\n",
    "print (\"done:\", done)\n",
    "done+=1\n",
    "## kinetic in cons\n",
    "train_df[\"kinetic_cons\"] = train_df[\"comment_text\"].apply(kinetic_cons)\n",
    "test_df[\"kinetic_cons\"] = test_df[\"comment_text\"].apply(kinetic_cons)\n",
    "print (\"done:\", done)\n",
    "done+=1\n",
    "## kinetic in ponct\n",
    "train_df[\"kinetic_ponct\"] = train_df[\"comment_text\"].apply(kinetic_ponct)\n",
    "test_df[\"kinetic_ponct\"] = test_df[\"comment_text\"].apply(kinetic_ponct)\n",
    "print (\"done:\", done)\n",
    "done+=1\n",
    "## kinetic in ponct\n",
    "train_df[\"kinetic_avg_words\"] = train_df[\"comment_text\"].apply(kinetic_average_words)\n",
    "test_df[\"kinetic_avg_words\"] = test_df[\"comment_text\"].apply(kinetic_average_words)\n",
    "print (\"done:\", done)\n",
    "done+=1\n",
    "## Number of words in the text ##\n",
    "train_df[\"num_words\"] = train_df[\"comment_text\"].apply(lambda x: len(str(x).split()))\n",
    "test_df[\"num_words\"] = test_df[\"comment_text\"].apply(lambda x: len(str(x).split()))\n",
    "print (\"done:\", done)\n",
    "done+=1\n",
    "## Number of unique words in the text ##\n",
    "train_df[\"num_unique_words\"] = train_df[\"comment_text\"].apply(lambda x: len(set(str(x).split())))\n",
    "test_df[\"num_unique_words\"] = test_df[\"comment_text\"].apply(lambda x: len(set(str(x).split())))\n",
    "print (\"done:\", done)\n",
    "done+=1\n",
    "## Number of characters in the text ##\n",
    "train_df[\"num_chars\"] = train_df[\"comment_text\"].apply(lambda x: len(str(x)))\n",
    "test_df[\"num_chars\"] = test_df[\"comment_text\"].apply(lambda x: len(str(x)))\n",
    "print (\"done:\", done)\n",
    "done+=1\n",
    "## Number of stopwords in the text ##\n",
    "train_df[\"num_stopwords\"] = train_df[\"comment_text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n",
    "test_df[\"num_stopwords\"] = test_df[\"comment_text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n",
    "print (\"done:\", done)\n",
    "done+=1\n",
    "## Number of punctuations in the text ##\n",
    "train_df[\"num_punctuations\"] =train_df['comment_text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n",
    "test_df[\"num_punctuations\"] =test_df['comment_text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n",
    "print (\"done:\", done)\n",
    "done+=1\n",
    "# Number of conconnes in the text ##\n",
    "\n",
    "\n",
    "## Number of title case words in the text ##\n",
    "train_df[\"num_words_upper\"] = train_df[\"comment_text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "test_df[\"num_words_upper\"] = test_df[\"comment_text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "print (\"done:\", done)\n",
    "done+=1\n",
    "## Number of title case words in the text ##\n",
    "train_df[\"num_words_title\"] = train_df[\"comment_text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "test_df[\"num_words_title\"] = test_df[\"comment_text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "print (\"done:\", done)\n",
    "done+=1\n",
    "## Average length of the words in the text ##\n",
    "train_df[\"mean_word_len\"] = train_df[\"comment_text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "test_df[\"mean_word_len\"] = test_df[\"comment_text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "print (\"done:\", done)\n",
    "done+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = feature_extraction.text.TfidfVectorizer(stop_words='english', max_features=50000)\n",
    "data = vectorizer.fit_transform(df)\n",
    "\n",
    "model = ensemble.ExtraTreesClassifier(n_jobs=-1, random_state=3)\n",
    "model.fit(data[:nrow], y)\n",
    "print(1- model.score(data[:nrow], y))\n",
    "sumbission = pd.DataFrame(model.predict(data[nrow:]))\n",
    "submission.columns = coly\n",
    "submission['id'] = test_id\n",
    "\n",
    "sumbission.columns = [x+'_' if x not in ['id'] else x for x in sub2.columns]\n",
    "blend = pd.merge(sample, submission, how='left', on='id')\n",
    "for c in coly:\n",
    "    blend[c] = blend[c] * 0.9 + blend[c+'_'] * 0.1\n",
    "    blend[c] = blend[c].clip(0+1e12, 1-1e12)\n",
    "final = blend[sample.columns]\n",
    "final.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
